{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More rnn layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.sparse import csr_matrix\n",
    "from detoxify import Detoxify\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import os\n",
    "import string\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "\n",
    "chencherry = SmoothingFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_path = '../data/internal/data.csv'\n",
    "train_file_path = '../data/internal/train_data.csv'\n",
    "valid_file_path = '../data/internal/valid_data.csv'\n",
    "test_file_path = '../data/internal/test_data.csv'\n",
    "\n",
    "data = pd.read_csv(data_file_path)\n",
    "train_data = pd.read_csv(train_file_path)\n",
    "valid_data = pd.read_csv(valid_file_path)\n",
    "test_data = pd.read_csv(test_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_data.sample(n = 15000, random_state=1)\n",
    "valid_df = valid_data.sample(n = 1500, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    \"\"\"\n",
    "    Removes punctuation from text\n",
    "\n",
    "    :param text: text to remove punctuation from\n",
    "    :return: text without punctuation\n",
    "    \"\"\"\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['reference'] = train_df['reference'].apply(remove_punctuation)\n",
    "train_df['translation'] = train_df['translation'].apply(remove_punctuation)\n",
    "\n",
    "valid_df['reference'] = valid_df['reference'].apply(remove_punctuation)\n",
    "valid_df['translation'] = valid_df['translation'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>similarity</th>\n",
       "      <th>lenght_diff</th>\n",
       "      <th>ref_tox</th>\n",
       "      <th>trn_tox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92781</th>\n",
       "      <td>254295</td>\n",
       "      <td>this thing is dead</td>\n",
       "      <td>Thats dead</td>\n",
       "      <td>0.847450</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.875859</td>\n",
       "      <td>0.003970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33273</th>\n",
       "      <td>146878</td>\n",
       "      <td>you shut up I wanna see it</td>\n",
       "      <td>You close your eyes I wanna see</td>\n",
       "      <td>0.653026</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.998420</td>\n",
       "      <td>0.000834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22857</th>\n",
       "      <td>311558</td>\n",
       "      <td>I thought Id be fucked but Im not</td>\n",
       "      <td>I thought I was gonna be really upset but Im n...</td>\n",
       "      <td>0.660462</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.996695</td>\n",
       "      <td>0.000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18739</th>\n",
       "      <td>297481</td>\n",
       "      <td>resistance is useless so</td>\n",
       "      <td>Resistance is futile so</td>\n",
       "      <td>0.934338</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.778996</td>\n",
       "      <td>0.000562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102410</th>\n",
       "      <td>325100</td>\n",
       "      <td>what the hell is going on</td>\n",
       "      <td>What the devils going on in here</td>\n",
       "      <td>0.787813</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.900568</td>\n",
       "      <td>0.013883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                          reference  \\\n",
       "92781   254295                 this thing is dead   \n",
       "33273   146878         you shut up I wanna see it   \n",
       "22857   311558  I thought Id be fucked but Im not   \n",
       "18739   297481           resistance is useless so   \n",
       "102410  325100          what the hell is going on   \n",
       "\n",
       "                                              translation  similarity  \\\n",
       "92781                                          Thats dead    0.847450   \n",
       "33273                     You close your eyes I wanna see    0.653026   \n",
       "22857   I thought I was gonna be really upset but Im n...    0.660462   \n",
       "18739                            Resistance is futile so     0.934338   \n",
       "102410                   What the devils going on in here    0.787813   \n",
       "\n",
       "        lenght_diff   ref_tox   trn_tox  \n",
       "92781      0.350000  0.875859  0.003970  \n",
       "33273      0.147059  0.998420  0.000834  \n",
       "22857      0.344828  0.996695  0.000051  \n",
       "18739      0.034483  0.778996  0.000562  \n",
       "102410     0.228571  0.900568  0.013883  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_texts = pd.concat([train_df['reference'], valid_df['reference'], test_df['reference']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_tokenize(sentence):\n",
    "    \"\"\"\n",
    "    Tokenize a sentence using NLTK.\n",
    "\n",
    "    :param sentence: The sentence to tokenize.\n",
    "    :return: The tokenized sentence.\n",
    "    \"\"\"\n",
    "    return nltk.word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(tokenized_texts):\n",
    "    \"\"\"\n",
    "    Build a vocabulary from a list of tokenized texts.\n",
    "\n",
    "    :param tokenized_texts: A list of tokenized texts.\n",
    "    :return: The vocabulary.\n",
    "    \"\"\"\n",
    "    counter = Counter()\n",
    "    for tokens in tokenized_texts:\n",
    "        counter.update(tokens)\n",
    "\n",
    "    vocab = {'<pad>': 0, '<unk>': 1}\n",
    "    for token, freq in counter.items():\n",
    "        vocab[token] = len(vocab)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_indices(tokenized_sentence, vocab):\n",
    "    \"\"\"\n",
    "    Convert a tokenized sentence to a list of indices using a vocabulary.\n",
    "\n",
    "    :param tokenized_sentence: The tokenized sentence.\n",
    "    :param vocab: The vocabulary.\n",
    "    :return: The list of indices.\n",
    "    \"\"\"\n",
    "    return [vocab.get(token, vocab['<unk>']) for token in tokenized_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence(seq, max_length):\n",
    "    \"\"\"\n",
    "    Pad a sequence to a maximum length.\n",
    "\n",
    "    :param seq: The sequence to pad.\n",
    "    :param max_length: The maximum length.\n",
    "    :return: The padded sequence.\n",
    "    \"\"\"\n",
    "    seq += [vocab['<pad>']] * (max_length - len(seq))\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices_to_tokens(indices, vocab):\n",
    "    \"\"\"\n",
    "    Convert a list of indices to a list of tokens using a vocabulary.\n",
    "\n",
    "    :param indices: The list of indices.\n",
    "    :param vocab: The vocabulary.\n",
    "    :return: The list of tokens.\n",
    "    \"\"\"\n",
    "    inv_vocab = {index: token for token, index in vocab.items()}\n",
    "    return [inv_vocab.get(index, '<unk>') for index in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices_to_text(indices, vocab):\n",
    "    \"\"\"\n",
    "    Convert a list of indices to a text using a vocabulary.\n",
    "\n",
    "    :param indices: The list of indices.\n",
    "    :param vocab: The vocabulary.\n",
    "    :return: The text.\n",
    "    \"\"\"\n",
    "    index_to_word = {index: word for word, index in vocab.items()}\n",
    "    \n",
    "    return ' '.join(index_to_word.get(index, '<unk>') for index in indices if index != vocab['<pad>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_texts = [nltk_tokenize(sentence) for sentence in train_df['reference']]\n",
    "vocab = build_vocab(tokenized_texts)\n",
    "max_length = max(len(tokens) for tokens in tokenized_texts)\n",
    "total_vocab_size = len(vocab)\n",
    "\n",
    "tokenized_val_texts = [nltk_tokenize(sentence) for sentence in valid_df['reference']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, tokenized_texts, vocab, max_length):\n",
    "        self.tokenized_texts = tokenized_texts\n",
    "        self.vocab = vocab\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokenized_texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        indices = tokens_to_indices(self.tokenized_texts[idx], self.vocab)\n",
    "        source = pad_sequence(indices, self.max_length)\n",
    "        target = pad_sequence(indices[1:], self.max_length)\n",
    "        return torch.tensor(source, dtype=torch.long), torch.tensor(target, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextDataset(tokenized_texts, vocab, max_length)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = TextDataset(tokenized_val_texts, vocab, max_length)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers, dropout_rate):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers=num_layers, \n",
    "                            batch_first=True, dropout=dropout_rate if num_layers > 1 else 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "        return hidden, cell\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers, dropout_rate):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers=num_layers, \n",
    "                            batch_first=True, dropout=dropout_rate if num_layers > 1 else 0)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
    "        prediction = self.fc(output)\n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, source, target):\n",
    "        hidden, cell = self.encoder(source)\n",
    "        prediction, hidden, cell = self.decoder(target, hidden, cell)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_rate = 0.5\n",
    "num_layers = 3\n",
    "\n",
    "encoder = Encoder(\n",
    "    vocab_size=total_vocab_size,\n",
    "    embed_size=128,\n",
    "    hidden_size=128,\n",
    "    num_layers=num_layers,\n",
    "    dropout_rate=dropout_rate\n",
    ").to(device)\n",
    "\n",
    "decoder = Decoder(\n",
    "    vocab_size=total_vocab_size,\n",
    "    embed_size=128,\n",
    "    hidden_size=128,\n",
    "    num_layers=num_layers,\n",
    "    dropout_rate=dropout_rate\n",
    ").to(device)\n",
    "\n",
    "seq2seq = Seq2Seq(encoder, decoder).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = torch.optim.Adam(seq2seq.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Custon metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxicity_model = Detoxify('original')\n",
    "similarity_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_toxicity_scores(texts, toxicity_model):\n",
    "    \"\"\"\n",
    "    Get the toxicity scores for a batch of texts.\n",
    "    :param texts: The list of texts to get toxicity scores for.\n",
    "    :param toxicity_model: The pre-loaded toxicity model.\n",
    "    :return: The list of toxicity scores for the given texts.\n",
    "    \"\"\"\n",
    "    results = toxicity_model.predict(texts)\n",
    "    return results['toxicity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_batch_semantic_similarity(original_texts, detoxified_texts, similarity_model):\n",
    "    \"\"\"\n",
    "    Calculate the semantic similarity between batches of original texts and their detoxified versions.\n",
    "    :param original_texts: The list of original texts.\n",
    "    :param detoxified_texts: The list of detoxified texts.\n",
    "    :param similarity_model: The pre-loaded sentence similarity model.\n",
    "    :return: The list of semantic similarity scores between the two batches of texts.\n",
    "    \"\"\"\n",
    "    original_embeddings = similarity_model.encode(original_texts, convert_to_tensor=True)\n",
    "    detoxified_embeddings = similarity_model.encode(detoxified_texts, convert_to_tensor=True)\n",
    "    similarity_scores = cdist(original_embeddings.cpu().numpy(), detoxified_embeddings.cpu().numpy(), metric='cosine')\n",
    "    return 1 - similarity_scores.diagonal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_custom_metric(references, predictions, toxicity_model, similarity_model, device):\n",
    "    \"\"\"\n",
    "    Calculate the custom metric for a batch of references and predictions.\n",
    "\n",
    "    :param references: The list of references.\n",
    "    :param predictions: The list of predictions.\n",
    "    :param toxicity_model: The pre-loaded toxicity model.\n",
    "    :param similarity_model: The pre-loaded sentence similarity model.\n",
    "    :param device: The device to use.\n",
    "    :return: The list of custom metric scores for the given references and predictions.\n",
    "    \"\"\"\n",
    "    custom_scores = []\n",
    "    for ref, pred in tqdm(zip(references, predictions), total=len(references), desc=\"Calculating Metrics\", leave=False):\n",
    "        ref_lower = ref.lower()\n",
    "        pred_lower = pred.lower()\n",
    "\n",
    "        # BLEU score\n",
    "        bleu_score = sentence_bleu([ref_lower.split()], pred_lower.split(), smoothing_function=SmoothingFunction().method1)\n",
    "\n",
    "        # Get toxicity score for the predicted text\n",
    "        detoxified_toxicity = toxicity_model.predict([pred_lower])['toxicity'][0]\n",
    "\n",
    "        # Get embeddings for original and predicted texts\n",
    "        original_embedding = similarity_model.encode(ref_lower, convert_to_tensor=True).to(device)\n",
    "        detoxified_embedding = similarity_model.encode(pred_lower, convert_to_tensor=True).to(device)\n",
    "\n",
    "        # Ensure the embeddings are 1D tensors\n",
    "        original_embedding = original_embedding.squeeze()\n",
    "        detoxified_embedding = detoxified_embedding.squeeze()\n",
    "\n",
    "        # Compute cosine similarity\n",
    "        similarity = torch.nn.functional.cosine_similarity(original_embedding.unsqueeze(0), detoxified_embedding.unsqueeze(0))\n",
    "\n",
    "        # Custom score calculation\n",
    "        custom_score = bleu_score * (1 - abs(detoxified_toxicity)) * similarity.item()\n",
    "        custom_scores.append(custom_score)\n",
    "\n",
    "    return custom_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, toxicity_model, similarity_model, device):\n",
    "    \"\"\"\n",
    "    Validate the model on a validation set.\n",
    "\n",
    "    :param model: The model to validate.\n",
    "    :param val_loader: The validation data loader.\n",
    "    :param toxicity_model: The pre-loaded toxicity model.\n",
    "    :param similarity_model: The pre-loaded sentence similarity model.\n",
    "    :param device: The device to run the similarity model on.\n",
    "    :return: The average custom score for the given model and validation data.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    custom_scores = []\n",
    "    references = []\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for source, target in tqdm(val_loader, desc=\"Validating\", leave=False):\n",
    "            source, target = source.to(device), target.to(device)\n",
    "            output = model(source, target[:, :-1])\n",
    "            predicted_indices = output.argmax(-1)\n",
    "            pred_texts = [' '.join(indices_to_tokens(indices.cpu().numpy(), vocab)) for indices in predicted_indices]\n",
    "            ref_texts = [' '.join(indices_to_tokens(indices.cpu().numpy(), vocab)) for indices in target[:, 1:]]\n",
    "            predictions.extend(pred_texts)\n",
    "            references.extend(ref_texts)\n",
    "            \n",
    "    custom_scores = calculate_custom_metric(references, predictions, toxicity_model, similarity_model, device)\n",
    "    return np.mean(custom_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and validation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 235/235 [03:14<00:00,  1.54batch/s, loss=2.25]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved after epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 235/235 [07:11<00:00,  1.54batch/s, loss=2.25]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished with score 9.669683673113766e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 235/235 [07:11<00:00,  1.84s/batch, loss=2.25]\n",
      "Epoch 2/5: 100%|██████████| 235/235 [04:13<00:00,  1.26batch/s, loss=1.82]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved after epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 235/235 [08:03<00:00,  2.06s/batch, loss=1.82]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished with score 4.984691303307479e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/5: 100%|██████████| 235/235 [04:12<00:00,  1.24batch/s, loss=1.78]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved after epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 235/235 [07:58<00:00,  1.24batch/s, loss=1.78]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished with score 2.9602228363757685e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 235/235 [07:59<00:00,  2.04s/batch, loss=1.78]\n",
      "Epoch 4/5: 100%|██████████| 235/235 [04:09<00:00,  1.17batch/s, loss=1.69]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved after epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 235/235 [08:14<00:00,  2.10s/batch, loss=1.69]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished with score 2.9602228363757685e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/5: 100%|██████████| 235/235 [04:17<00:00,  1.18batch/s, loss=1.68]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved after epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 235/235 [08:13<00:00,  1.18batch/s, loss=1.68]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished with score 7.833120735647453e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 235/235 [08:13<00:00,  2.10s/batch, loss=1.68]\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "accumulation_steps = 4\n",
    "best_metric = float('-inf')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with tqdm(total=len(train_loader), desc=f\"Epoch {epoch + 1}/{epochs}\", unit='batch') as pbar:\n",
    "        seq2seq.train()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        for batch_idx, (source, target) in enumerate(train_loader):\n",
    "\n",
    "            seq2seq.train()\n",
    "\n",
    "            source, target = source.to(device), target.to(device)\n",
    "            \n",
    "            output = seq2seq(source, target[:, :-1])\n",
    "            loss = loss_function(output.permute(0, 2, 1), target[:, 1:])\n",
    "            loss = loss / accumulation_steps\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            if (batch_idx + 1) % accumulation_steps == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "            pbar.update(1)\n",
    "            \n",
    "            # Free up memory\n",
    "            if device.type == 'cuda':\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            gc.collect()\n",
    "        \n",
    "        # End of epoch cleanup\n",
    "        checkpoint_path = os.path.join(\"../models/checkpoints/\", f\"model_3.2_epoch_{epoch+1}.pt\")\n",
    "        pbar.write(f\"Checkpoint saved after epoch {epoch+1}\")\n",
    "        \n",
    "        # Validate the model\n",
    "        seq2seq.eval()\n",
    "\n",
    "        val_metric = validate(seq2seq, val_loader, toxicity_model, similarity_model, device)\n",
    "        if val_metric > best_metric:\n",
    "            best_metric = val_metric\n",
    "            best_model_path = '../models/3.2-custom-embeddings.pt'\n",
    "            torch.save(seq2seq.state_dict(), best_model_path)\n",
    "        \n",
    "        pbar.write(f\"Finished with score {val_metric}\")\n",
    "        \n",
    "        # Cleanup at the end of the epoch\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training takes a lot of time even when training on the gpu (about 5-6 hour for 1 epoch) for all dataset (not sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_model = Seq2Seq(encoder, decoder).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_processor(texts, max_len, tokenizer, vocab):\n",
    "    \"\"\"\n",
    "    Process a list of texts into padded sequences for PyTorch.\n",
    "    :param texts: The list of texts to process.\n",
    "    :param max_len: The maximum length of the sequences.\n",
    "    :param tokenizer: The tokenizer function to use.\n",
    "    :param vocab: The vocabulary to use for token to index conversion.\n",
    "    :return: A tensor of padded sequences.\n",
    "    \"\"\"\n",
    "    tokenized_texts = [tokenizer(text) for text in texts]\n",
    "    indexed_texts = [tokens_to_indices(t, vocab) for t in tokenized_texts]\n",
    "    padded_texts = [pad_sequence(t, max_len) for t in indexed_texts]\n",
    "    return torch.tensor(padded_texts, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>similarity</th>\n",
       "      <th>lenght_diff</th>\n",
       "      <th>ref_tox</th>\n",
       "      <th>trn_tox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>289945</td>\n",
       "      <td>the curse of death is on him!</td>\n",
       "      <td>It's got a death curse!</td>\n",
       "      <td>0.845815</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.876750</td>\n",
       "      <td>0.006088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>480510</td>\n",
       "      <td>but then you'll know I'm gonna beat you up by ...</td>\n",
       "      <td>But then, you'll know deep down that I beat yo...</td>\n",
       "      <td>0.788745</td>\n",
       "      <td>0.085271</td>\n",
       "      <td>0.963052</td>\n",
       "      <td>0.000903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>107858</td>\n",
       "      <td>Blondie, come out, 3 seconds, and you'll burn.</td>\n",
       "      <td>Blondie Come on out 3 seconds and you burn One...</td>\n",
       "      <td>0.799032</td>\n",
       "      <td>0.203390</td>\n",
       "      <td>0.992113</td>\n",
       "      <td>0.016989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39034</td>\n",
       "      <td>everyone knows if a woman starts poking her no...</td>\n",
       "      <td>Everyone knows when a bird starts poking her n...</td>\n",
       "      <td>0.862760</td>\n",
       "      <td>0.164948</td>\n",
       "      <td>0.706885</td>\n",
       "      <td>0.000631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>140946</td>\n",
       "      <td>and your eyes, my God, have smoked my foetus.</td>\n",
       "      <td>And Your eyes, my God, they have seen me in th...</td>\n",
       "      <td>0.767273</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.973932</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                          reference  \\\n",
       "0  289945                      the curse of death is on him!   \n",
       "1  480510  but then you'll know I'm gonna beat you up by ...   \n",
       "2  107858     Blondie, come out, 3 seconds, and you'll burn.   \n",
       "3   39034  everyone knows if a woman starts poking her no...   \n",
       "4  140946      and your eyes, my God, have smoked my foetus.   \n",
       "\n",
       "                                         translation  similarity  lenght_diff  \\\n",
       "0                            It's got a death curse!    0.845815     0.200000   \n",
       "1  But then, you'll know deep down that I beat yo...    0.788745     0.085271   \n",
       "2  Blondie Come on out 3 seconds and you burn One...    0.799032     0.203390   \n",
       "3  Everyone knows when a bird starts poking her n...    0.862760     0.164948   \n",
       "4  And Your eyes, my God, they have seen me in th...    0.767273     0.148148   \n",
       "\n",
       "    ref_tox   trn_tox  \n",
       "0  0.876750  0.006088  \n",
       "1  0.963052  0.000903  \n",
       "2  0.992113  0.016989  \n",
       "3  0.706885  0.000631  \n",
       "4  0.973932  0.000100  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test_data = test_data.sample(random_state=1, n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(12113, 128)\n",
       "    (lstm): LSTM(128, 128, num_layers=3, batch_first=True, dropout=0.5)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(12113, 128)\n",
       "    (lstm): LSTM(128, 128, num_layers=3, batch_first=True, dropout=0.5)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (fc): Linear(in_features=128, out_features=12113, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2seq.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = sample_test_data['reference'].tolist()\n",
    "test_seqs = sequence_processor(test_texts, max_length, nltk_tokenize, vocab)\n",
    "\n",
    "# Create a tensor for the second input with zeros\n",
    "test_seq_input_2 = torch.zeros_like(test_seqs)\n",
    "\n",
    "# Move the tensors to the correct device\n",
    "test_seqs, test_seq_input_2 = test_seqs.to(device), test_seq_input_2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    predictions_seq = seq2seq(test_seqs, test_seq_input_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_indices = predictions_seq.argmax(dim=-1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices_to_text(indices, vocab):\n",
    "    \"\"\"\n",
    "    Convert a list of indices to a text using a vocabulary.\n",
    "\n",
    "    :param indices: The list of indices to convert.\n",
    "    :param vocab: The vocabulary mapping words to indices.\n",
    "    :return: The text.\n",
    "    \"\"\"\n",
    "    if isinstance(indices, torch.Tensor):\n",
    "        indices = indices.tolist()\n",
    "\n",
    "    index_to_word = {index: word for word, index in vocab.items()}\n",
    "    return ' '.join(index_to_word.get(index, '<unk>') for index in indices if index != vocab['<pad>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_texts = [indices_to_text(seq, vocab) for seq in predicted_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test_data['predicted'] = predicted_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>similarity</th>\n",
       "      <th>lenght_diff</th>\n",
       "      <th>ref_tox</th>\n",
       "      <th>trn_tox</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3841</th>\n",
       "      <td>187371</td>\n",
       "      <td>\"a fool's mercy allowed me to escape.\"</td>\n",
       "      <td>\"A madman's mercy bade thee run away.\"</td>\n",
       "      <td>0.712329</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.993162</td>\n",
       "      <td>0.003678</td>\n",
       "      <td>the the the the the the the the the the the th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12898</th>\n",
       "      <td>201094</td>\n",
       "      <td>to invent crazy theories...... and look for me...</td>\n",
       "      <td>To keep us spinning wild theories and chasing ...</td>\n",
       "      <td>0.684736</td>\n",
       "      <td>0.091743</td>\n",
       "      <td>0.858899</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>the the the the the the the the the the the th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15032</th>\n",
       "      <td>575586</td>\n",
       "      <td>I'm afraid they're both dead.</td>\n",
       "      <td>Dead of their wounds, I'm afraid, both of them.</td>\n",
       "      <td>0.770305</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.982602</td>\n",
       "      <td>0.003361</td>\n",
       "      <td>the the the the the the the the the the the th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36781</th>\n",
       "      <td>210240</td>\n",
       "      <td>we get rid of criminals so they can't hurt peo...</td>\n",
       "      <td>We put bad guys away... ...where they can't hu...</td>\n",
       "      <td>0.692323</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.955471</td>\n",
       "      <td>0.003611</td>\n",
       "      <td>the the the the the the the the the the the th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9201</th>\n",
       "      <td>32007</td>\n",
       "      <td>my little girl came home and found your disgus...</td>\n",
       "      <td>My little girl has to come home and find your ...</td>\n",
       "      <td>0.928549</td>\n",
       "      <td>0.037975</td>\n",
       "      <td>0.713162</td>\n",
       "      <td>0.004013</td>\n",
       "      <td>the the the the the the the the the the the th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                          reference  \\\n",
       "3841   187371             \"a fool's mercy allowed me to escape.\"   \n",
       "12898  201094  to invent crazy theories...... and look for me...   \n",
       "15032  575586                      I'm afraid they're both dead.   \n",
       "36781  210240  we get rid of criminals so they can't hurt peo...   \n",
       "9201    32007  my little girl came home and found your disgus...   \n",
       "\n",
       "                                             translation  similarity  \\\n",
       "3841              \"A madman's mercy bade thee run away.\"    0.712329   \n",
       "12898  To keep us spinning wild theories and chasing ...    0.684736   \n",
       "15032    Dead of their wounds, I'm afraid, both of them.    0.770305   \n",
       "36781  We put bad guys away... ...where they can't hu...    0.692323   \n",
       "9201   My little girl has to come home and find your ...    0.928549   \n",
       "\n",
       "       lenght_diff   ref_tox   trn_tox  \\\n",
       "3841      0.000000  0.993162  0.003678   \n",
       "12898     0.091743  0.858899  0.000959   \n",
       "15032     0.375000  0.982602  0.003361   \n",
       "36781     0.105263  0.955471  0.003611   \n",
       "9201      0.037975  0.713162  0.004013   \n",
       "\n",
       "                                               predicted  \n",
       "3841   the the the the the the the the the the the th...  \n",
       "12898  the the the the the the the the the the the th...  \n",
       "15032  the the the the the the the the the the the th...  \n",
       "36781  the the the the the the the the the the the th...  \n",
       "9201   the the the the the the the the the the the th...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    }
   ],
   "source": [
    "custom_scores = calculate_custom_metric(\n",
    "    references=sample_test_data['reference'].tolist(),\n",
    "    predictions=sample_test_data['predicted'].tolist(),\n",
    "    toxicity_model=toxicity_model,\n",
    "    similarity_model=similarity_model,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test_data['custom_score'] = custom_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>similarity</th>\n",
       "      <th>lenght_diff</th>\n",
       "      <th>ref_tox</th>\n",
       "      <th>trn_tox</th>\n",
       "      <th>predicted</th>\n",
       "      <th>custom_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3841</th>\n",
       "      <td>187371</td>\n",
       "      <td>\"a fool's mercy allowed me to escape.\"</td>\n",
       "      <td>\"A madman's mercy bade thee run away.\"</td>\n",
       "      <td>0.712329</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.993162</td>\n",
       "      <td>0.003678</td>\n",
       "      <td>the the the the the the the the the the the th...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12898</th>\n",
       "      <td>201094</td>\n",
       "      <td>to invent crazy theories...... and look for me...</td>\n",
       "      <td>To keep us spinning wild theories and chasing ...</td>\n",
       "      <td>0.684736</td>\n",
       "      <td>0.091743</td>\n",
       "      <td>0.858899</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>the the the the the the the the the the the th...</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15032</th>\n",
       "      <td>575586</td>\n",
       "      <td>I'm afraid they're both dead.</td>\n",
       "      <td>Dead of their wounds, I'm afraid, both of them.</td>\n",
       "      <td>0.770305</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.982602</td>\n",
       "      <td>0.003361</td>\n",
       "      <td>the the the the the the the the the the the th...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36781</th>\n",
       "      <td>210240</td>\n",
       "      <td>we get rid of criminals so they can't hurt peo...</td>\n",
       "      <td>We put bad guys away... ...where they can't hu...</td>\n",
       "      <td>0.692323</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.955471</td>\n",
       "      <td>0.003611</td>\n",
       "      <td>the the the the the the the the the the the th...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9201</th>\n",
       "      <td>32007</td>\n",
       "      <td>my little girl came home and found your disgus...</td>\n",
       "      <td>My little girl has to come home and find your ...</td>\n",
       "      <td>0.928549</td>\n",
       "      <td>0.037975</td>\n",
       "      <td>0.713162</td>\n",
       "      <td>0.004013</td>\n",
       "      <td>the the the the the the the the the the the th...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                          reference  \\\n",
       "3841   187371             \"a fool's mercy allowed me to escape.\"   \n",
       "12898  201094  to invent crazy theories...... and look for me...   \n",
       "15032  575586                      I'm afraid they're both dead.   \n",
       "36781  210240  we get rid of criminals so they can't hurt peo...   \n",
       "9201    32007  my little girl came home and found your disgus...   \n",
       "\n",
       "                                             translation  similarity  \\\n",
       "3841              \"A madman's mercy bade thee run away.\"    0.712329   \n",
       "12898  To keep us spinning wild theories and chasing ...    0.684736   \n",
       "15032    Dead of their wounds, I'm afraid, both of them.    0.770305   \n",
       "36781  We put bad guys away... ...where they can't hu...    0.692323   \n",
       "9201   My little girl has to come home and find your ...    0.928549   \n",
       "\n",
       "       lenght_diff   ref_tox   trn_tox  \\\n",
       "3841      0.000000  0.993162  0.003678   \n",
       "12898     0.091743  0.858899  0.000959   \n",
       "15032     0.375000  0.982602  0.003361   \n",
       "36781     0.105263  0.955471  0.003611   \n",
       "9201      0.037975  0.713162  0.004013   \n",
       "\n",
       "                                               predicted  custom_score  \n",
       "3841   the the the the the the the the the the the th...           0.0  \n",
       "12898  the the the the the the the the the the the th...          -0.0  \n",
       "15032  the the the the the the the the the the the th...           0.0  \n",
       "36781  the the the the the the the the the the the th...           0.0  \n",
       "9201   the the the the the the the the the the the th...           0.0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the distribution of custom scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(custom_scores, bins=50, alpha=0.7, color='blue')\n",
    "plt.title('Distribution of Custom Scores')\n",
    "plt.xlabel('Custom Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
